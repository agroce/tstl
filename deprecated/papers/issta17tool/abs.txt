Test reduction has long been seen as critical for automated testing.  However, traditional test reduction simply reduces the length of a test, but does not attempt to reduce semantic complexity.  This paper extends previous efforts with algorithms for normalizing and generalizing tests.  Rewriting tests into a normal form can reduce semantic complexity and even remove steps from an already delta-debugged test.  Moreover, normalization dramatically reduces the number of tests that a reader must examine, partially addressing the ``fuzzer taming'' problem of discovering distinct faults in a set of failing tests.  Generalization, in contrast, takes a test and reports what aspects of the test could have been changed while preserving the property that the test fails.  Normalization plus generalization aids understanding of tests, including tests for complex and widely used APIs such as the NumPy numeric computation library and the ArcPy GIS scripting package.  Normalization frequently reduces the number of tests to be examined by well over an order of magnitude, and often to just one test per fault.  Together, ideally, normalization and generalization allow a user to replace reading a large set of tests that vary in unimportant ways with reading one annotated summary test.
